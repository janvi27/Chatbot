{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk as nlp\n",
    "import sklearn\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>When you book a hotel room online, you expect ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>It’s tough enough to find a job or start your ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>The Federal Trade Commission cracked down on a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>\"There is currently money available NOW right ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>It's enough to make you sick. No sooner had th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0      [During anti-police-brutality protests that sw...      0\n",
       "1      [In June 2020, a rumor started to circulate on...      0\n",
       "2      [Rumors are surging in the wake of George Floy...      0\n",
       "3      [On June 4, 2020, a security fence was erected...      0\n",
       "4      [In early June 2020, social media users shared...      0\n",
       "...                                                  ...    ...\n",
       "10370  When you book a hotel room online, you expect ...      4\n",
       "10371  It’s tough enough to find a job or start your ...      4\n",
       "10372  The Federal Trade Commission cracked down on a...      4\n",
       "10373  \"There is currently money available NOW right ...      4\n",
       "10374  It's enough to make you sick. No sooner had th...      4\n",
       "\n",
       "[10375 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fake['label'] = 0\n",
    "#real['label'] = 1\n",
    "data = pd.read_csv('./Snopes-data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Text']\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing:\n",
    "X = X.str.lower()\n",
    "X = X.str.replace('[^\\w\\s]','')\n",
    "X = X.apply(lambda row: nlp.word_tokenize(row))\n",
    "stop = nlp.corpus.stopwords.words('english')\n",
    "X = X.apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf = True, min_df = 5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english', lowercase=False, max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_tfidf, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = [0]*5\n",
    "count_test = [0]*5\n",
    "for a in y_train:\n",
    "    count_train[a] = count_train[a] + 1\n",
    "print(count_train)\n",
    "for a in y_test:\n",
    "    count_test[a] = count_test[a] + 1\n",
    "print(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieLabels = ['Fake','Real','Mixture','Miscaptioned','Scam']\n",
    "figureObject, axesObject = plt.pyplot.subplots()\n",
    "axesObject.pie(count_train, labels = pieLabels, autopct='%1.2f', startangle=90)\n",
    "axesObject.axis('equal')\n",
    "plt.pyplot.show()\n",
    "figureObject, axesObject = plt.pyplot.subplots()\n",
    "axesObject.pie(count_test, labels = pieLabels, autopct='%1.2f', startangle=90)\n",
    "axesObject.axis('equal')\n",
    "plt.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6276903308705429"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.98      0.59       819\n",
      "           1       1.00      0.65      0.78       908\n",
      "           2       0.87      0.40      0.55       579\n",
      "           3       0.97      0.43      0.59       392\n",
      "           4       0.92      0.40      0.55       415\n",
      "\n",
      "    accuracy                           0.63      3113\n",
      "   macro avg       0.83      0.57      0.61      3113\n",
      "weighted avg       0.81      0.63      0.63      3113\n",
      "\n",
      "[[801   0  18   0   0]\n",
      " [283 587  17   6  15]\n",
      " [346   0 233   0   0]\n",
      " [224   0   0 168   0]\n",
      " [249   1   0   0 165]]\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "#precision: Number of true positives divided by total number of data points labelled positive, ie. TP/(TP + FP)\n",
    "#recall: proportion of positives which were labelled correctly, ie. TP/(TP + FN)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, prediction))\n",
    "print(confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[0.1,1,10,100,1000], 'gamma':[1, 0.1, 0.01, 0.001, 0.0001], 'kernel':['rbf']}\n",
    "grid = GridSearchCV(classifier, param_grid, refit = True, verbose = 3)\n",
    "grid.fit(X_train_tfidf, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_grid_params = {'C': [90,95,100,105,110],'gamma':[0.009,0.01,0.02], 'kernel':['rbf']}\n",
    "fine_grid = GridSearchCV(classifier, fine_grid_params, refit = True, verbose = 3)\n",
    "fine_grid.fit(X_train_tfidf, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_predictions = grid.predict(X_test_counts)\n",
    "#print(classification_report(y_test, grid_predictions))\n",
    "#accuracy = metrics.accuracy_score(y_test, grid_predictions)\n",
    "#print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "labels = y\n",
    "models = [RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), LinearSVC(), MultinomialNB(), LogisticRegression(random_state=0),]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['NEW DELHI: An Air India aircraft winging its way from Delhi to Moscow on Saturday morning had to be called back to Delhi from over Uzbekistan after the airline realised that one of the pilots onboard had tested corona positive. An oversight by the team checking pre-flight test reports of crew members had mistakenly read this captain’s positive report as negative and released him for the ferry flight (meaning with no passengers and only crew) to fly back Indians from Moscow.\\nThe Airbus A-320 Neo (VT-EXR) returned to Delhi at about 12.30 pm and now the crew will be quarantined as per norms. This plane will be fumigated and the airline is sending another A320 Neo to Moscow later on Saturday afternoon to fly back Indians from there.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
