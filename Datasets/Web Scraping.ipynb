{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings = {'false': 0, 'true': 1, 'mixture': 4, 'outdated': 6, 'miscaptioned': 7, 'scam': 10}\n",
    "ratings = {'false': 0, 'true': 1, 'mixture': 2, 'miscaptioned': 3, 'scam': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_content(weblinks, articles, key):\n",
    "    pagelinks = []\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append(url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        html = BeautifulSoup(requests.get(page).content, 'html.parser')\n",
    "        content = html.find_all('article')[0]\n",
    "        content = content.find_all('html')\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text, ratings[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ratings.keys():\n",
    "    for i in range(1,80):\n",
    "        if i==1:\n",
    "            page = requests.get(\"https://www.snopes.com/fact-check/rating/\" + key)\n",
    "        else:\n",
    "            page = requests.get(\"https://www.snopes.com/fact-check/rating/\" + key + \"/\" + str(i))\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        weblinks = soup.find_all('article')\n",
    "        page_content(weblinks, articles, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4375\n"
     ]
    }
   ],
   "source": [
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more miscaptioned articles from snopes\n",
    "for i in range(1,52):\n",
    "    if i==1:\n",
    "        page = requests.get(\"https://www.snopes.com/video/\")\n",
    "    else:\n",
    "        page = requests.get(\"https://www.snopes.com/video/\" + str(i) + \"/\")\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('article')\n",
    "    page_content(weblinks, articles, 'miscaptioned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>[In November 2018, after the Camp Fire broke o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>[As President Trump and his administration wer...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>[On 7 November 2018, a brief article published...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>[In early October 2018, First Lady Melania Tru...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>[On 28 October 2018, social media users shared...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4987 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "4982  [In November 2018, after the Camp Fire broke o...      3\n",
       "4983  [As President Trump and his administration wer...      3\n",
       "4984  [On 7 November 2018, a brief article published...      3\n",
       "4985  [In early October 2018, First Lady Melania Tru...      3\n",
       "4986  [On 28 October 2018, social media users shared...      3\n",
       "\n",
       "[4987 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)\n",
    "import pandas as pd\n",
    "pd.DataFrame(articles, columns = ['Text', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[875, 875, 875, 1487, 875]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0]*5\n",
    "for i in articles:\n",
    "    count[i[1]] = count[i[1]] + 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more mixture articles from politifact\n",
    "for i in range(1,37):\n",
    "    pagelinks = []\n",
    "    if i==1:\n",
    "        page  = requests.get('https://www.politifact.com/factchecks/list/?category=truth-o-meter&ruling=half-true')\n",
    "    else:\n",
    "        page = requests.get('https://www.politifact.com/factchecks/list/?page=' + str(i) + '&category=truth-o-meter&ruling=half-true')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('div', {'class':\"m-statement__quote\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.politifact.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        html = BeautifulSoup(requests.get(page).content, 'html.parser')\n",
    "        content = html.find_all('article', {'class':\"m-textblock\"})[0]\n",
    "        content = content.find_all('html')\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>[If you take away his religious-conservative v...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>[Standing on a stage in Iowa, amid all his com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6034</th>\n",
       "      <td>[For months, the antitax group Club for Growth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>[Under attack from Alan Keyes during a GOP deb...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>[In her speeches about the economy, Sen. Hilla...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6037 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "6032  [If you take away his religious-conservative v...      2\n",
       "6033  [Standing on a stage in Iowa, amid all his com...      2\n",
       "6034  [For months, the antitax group Club for Growth...      2\n",
       "6035  [Under attack from Alan Keyes during a GOP deb...      2\n",
       "6036  [In her speeches about the economy, Sen. Hilla...      2\n",
       "\n",
       "[6037 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(articles, columns = ['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in articles:\n",
    "    if len(a[0]) == 2:\n",
    "        articles.remove(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5646"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[797, 797, 1846, 1409, 797]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0]*5\n",
    "for i in articles:\n",
    "    count[i[1]] = count[i[1]] + 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(articles, columns = ['Text', 'Label'])\n",
    "temp.to_csv('news-temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "translator = Translator(to_lang = 'en')\n",
    "translated = translator.translate('Comment allez-vous')\n",
    "translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#false articles about coronavirus from poynter\n",
    "for i in range(1, 100):\n",
    "    if i==1:\n",
    "        url = ('https://www.poynter.org/ifcn-covid-19-misinformation/?covid_countries=0&covid_rating=51174&covid_fact_checkers=47485')\n",
    "    else:\n",
    "        url = ('https://www.poynter.org/ifcn-covid-19-misinformation/page/' + str(i) + '/?covid_countries=0&covid_rating=51174&covid_fact_checkers=47485#038;covid_rating=51174&covid_fact_checkers=47485')\n",
    "    r = urllib.request.Request(url, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    page = urllib.request.urlopen(r)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    weblinks = soup.find_all('h2', {'class':\"entry-title\"})\n",
    "    pagelinks = []\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append(url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        full_article = html.find_all('a',{'class':\"button entry-content__button entry-content__button--smaller\"})[0]\n",
    "        full_article_url = full_article.get('href')\n",
    "        r = urllib.request.Request(full_article_url, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        content = html.find_all('div',{'class':\"story-article__content__element--text\"})\n",
    "        print(content)\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div id=\"div-gpt-ad-1589720950581-0\" style=\"width: 1px; height: 1px;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1589720950581-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"div-gpt-ad-1589721120803-0\" style=\"width: 1px; height: 1px;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1589721120803-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"container\"></div>, <div id=\"div-gpt-ad-1588347376785-0\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1588347376785-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"div-gpt-ad-1508230408514-0\" style=\"display:none;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1508230408514-0'); });\n",
      "      </script>\n",
      "</div>]\n",
      "[<div id=\"div-gpt-ad-1589720950581-0\" style=\"width: 1px; height: 1px;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1589720950581-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"div-gpt-ad-1589721120803-0\" style=\"width: 1px; height: 1px;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1589721120803-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"container\"></div>, <div id=\"div-gpt-ad-1588347376785-0\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1588347376785-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"div-gpt-ad-1508230408514-0\" style=\"display:none;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1508230408514-0'); });\n",
      "      </script>\n",
      "</div>]\n",
      "[<div id=\"div-gpt-ad-1589720950581-0\" style=\"width: 1px; height: 1px;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1589720950581-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"div-gpt-ad-1589721120803-0\" style=\"width: 1px; height: 1px;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1589721120803-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"container\"></div>, <div id=\"div-gpt-ad-1588347376785-0\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1588347376785-0'); });\n",
      "      </script>\n",
      "</div>, <div id=\"div-gpt-ad-1508230408514-0\" style=\"display:none;\">\n",
      "<script>\n",
      "        googletag.cmd.push(function() { googletag.display('div-gpt-ad-1508230408514-0'); });\n",
      "      </script>\n",
      "</div>]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-30e1f287ecbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpagelinks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfull_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"button entry-content__button entry-content__button--smaller\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1368\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#checking\n",
    "url = ('https://www.poynter.org/ifcn-covid-19-misinformation/?covid_countries=0&covid_rating=51174&covid_fact_checkers=47485')\n",
    "r = urllib.request.Request(url, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "page = urllib.request.urlopen(r)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "weblinks = soup.find_all('h2', {'class':\"entry-title\"})\n",
    "pagelinks = []\n",
    "for link in weblinks:\n",
    "    url = link.find_all('a')[0]\n",
    "    pagelinks.append(url.get('href'))\n",
    "for page in pagelinks:\n",
    "    r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    news = urllib.request.urlopen(r)\n",
    "    html = BeautifulSoup(news, 'html.parser')\n",
    "    full_article = html.find_all('a',{'class':\"button entry-content__button entry-content__button--smaller\"})[0]\n",
    "    full_article_url = full_article.get('href')\n",
    "    r = urllib.request.Request(full_article_url, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    news = urllib.request.urlopen(r)\n",
    "    html = BeautifulSoup(news, 'html.parser')\n",
    "    content = html.find_all('div')\n",
    "    print(content)\n",
    "    clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "    text = clean_content.replace('\\n','')\n",
    "    text = text.replace('\\xa0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#false coronavirus articles from politifact\n",
    "for i in range(1,8):\n",
    "    pagelinks = []\n",
    "    if i==1:\n",
    "        page  = requests.get('https://www.politifact.com/factchecks/list/?category=coronavirus&ruling=false')\n",
    "    else:\n",
    "        page = requests.get('https://www.politifact.com/factchecks/list/?page=' + str(i) + '&category=coronavirus&ruling=false')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('div', {'class':\"m-statement__quote\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.politifact.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        html = BeautifulSoup(requests.get(page).content, 'html.parser')\n",
    "        content = html.find_all('article', {'class':\"m-textblock\"})[0]\n",
    "        content = content.find_all('html')\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#false coronavirus articles from politifact\n",
    "for i in range(1,4):\n",
    "    pagelinks = []\n",
    "    if i==1:\n",
    "        page  = requests.get('https://www.politifact.com/factchecks/list/?category=coronavirus&ruling=pants-fire')\n",
    "    else:\n",
    "        page = requests.get('https://www.politifact.com/factchecks/list/?page=' + str(i) + '&category=coronavirus&ruling=pants-fire')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('div', {'class':\"m-statement__quote\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.politifact.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        html = BeautifulSoup(requests.get(page).content, 'html.parser')\n",
    "        content = html.find_all('article', {'class':\"m-textblock\"})[0]\n",
    "        content = content.find_all('html')\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(articles, columns= ['Text', 'Label'])\n",
    "data.to_csv('news_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [0]*5\n",
    "for i in articles:\n",
    "    count[i[1]] = count[i[1]] + 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true articles about coronavirus from livemint\n",
    "for i in range(1, 100):\n",
    "    pagelinks = []\n",
    "    if i==1:\n",
    "        page = requests.get('https://www.livemint.com/topic/coronavirus')\n",
    "    else:\n",
    "        page = requests.get('https://www.livemint.com/topic/coronavirus/page-' + str(i))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('h2', {'class':\"headline\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.livemint.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        content = html.find_all('article')[0]\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7621</th>\n",
       "      <td>Nurses check the temperatures of visitors as p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>The diagnosis marks the first positive case of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7623</th>\n",
       "      <td>Only those who have proper permission of the o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7624</th>\n",
       "      <td>ICMR officials are in talks with at least 60-7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7625</th>\n",
       "      <td>There are over 6,000 Indian nationals in vario...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7626 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "7621  Nurses check the temperatures of visitors as p...      1\n",
       "7622  The diagnosis marks the first positive case of...      1\n",
       "7623  Only those who have proper permission of the o...      1\n",
       "7624  ICMR officials are in talks with at least 60-7...      1\n",
       "7625  There are over 6,000 Indian nationals in vario...      1\n",
       "\n",
       "[7626 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(articles, columns= ['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.livemint.com/topic/coronavirus')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "weblinks = soup.find_all('h2', {'class':\"headline\"})\n",
    "for link in weblinks:\n",
    "    url = link.find_all('a')[0]\n",
    "    pagelinks.append('https://www.livemint.com' + url.get('href'))\n",
    "for page in pagelinks:\n",
    "    r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    news = urllib.request.urlopen(r)\n",
    "    html = BeautifulSoup(news, 'html.parser')\n",
    "    content = html.find_all('article')[0]\n",
    "    clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "    text = clean_content.replace('\\n','')\n",
    "    text = text.replace('\\xa0', '')\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true articles about coronavirus from livemint\n",
    "for i in range(101, 200):\n",
    "    pagelinks = []\n",
    "    if i==1:\n",
    "        page = requests.get('https://www.livemint.com/topic/coronavirus')\n",
    "    else:\n",
    "        page = requests.get('https://www.livemint.com/topic/coronavirus/page-' + str(i))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('h2', {'class':\"headline\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.livemint.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        content = html.find_all('article')[0]\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7899</th>\n",
       "      <td>The coronavirus outbreak has disrupted flights...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7900</th>\n",
       "      <td>Odisha has not reported any positive case so f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7901</th>\n",
       "      <td>In the hypothetical worst-case scenarios for e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902</th>\n",
       "      <td>'All candidates who are scheduled to come onsi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7903</th>\n",
       "      <td>Testing facilities have been put in place in M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7904 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "7899  The coronavirus outbreak has disrupted flights...      1\n",
       "7900  Odisha has not reported any positive case so f...      1\n",
       "7901  In the hypothetical worst-case scenarios for e...      1\n",
       "7902  'All candidates who are scheduled to come onsi...      1\n",
       "7903  Testing facilities have been put in place in M...      1\n",
       "\n",
       "[7904 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(articles, columns = ['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2712, 3059, 1846, 1409, 1349]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0]*5\n",
    "for i in articles:\n",
    "    count[i[1]] = count[i[1]] + 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(articles, columns= ['Text', 'Label'])\n",
    "data.to_csv('news_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more articles on scams from livemint\n",
    "searches = ['https://www.livemint.com/Search/Link/Keyword/phish', 'https://www.livemint.com/Search/Link/Keyword/fraud', 'https://www.livemint.com/Search/Link/Keyword/scam']\n",
    "for search in searches:\n",
    "    page = requests.get(search)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('h2', {'class':\"headline\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.livemint.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        content = html.find_all('article')[0]\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>The meeting will be chaired by the health mini...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>These cyber attacks were aimed at heightening ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>A film producer said he recently ordered liquo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>Alexa is a voice-controlled virtual assistant ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>A file photo of Maharashtra home minister Anil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "7993  The meeting will be chaired by the health mini...      4\n",
       "7994  These cyber attacks were aimed at heightening ...      4\n",
       "7995  A film producer said he recently ordered liquo...      4\n",
       "7996  Alexa is a voice-controlled virtual assistant ...      4\n",
       "7997  A file photo of Maharashtra home minister Anil...      4\n",
       "\n",
       "[7998 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(articles, columns = ['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2712, 3059, 1846, 1409, 887]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0]*5\n",
    "for i in articles:\n",
    "    count[i[1]] = count[i[1]] + 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#true articles about coronavirus from livemint\n",
    "for i in range(201, 300):\n",
    "    pagelinks = []\n",
    "    if i==1:\n",
    "        page = requests.get('https://www.livemint.com/topic/coronavirus')\n",
    "    else:\n",
    "        page = requests.get('https://www.livemint.com/topic/coronavirus/page-' + str(i))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('h2', {'class':\"headline\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.livemint.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        content = html.find_all('article')[0]\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2712, 3059, 1846, 1409, 1349]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = [0]*5\n",
    "for i in articles:\n",
    "    count[i[1]] = count[i[1]] + 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>The meeting will be chaired by the health mini...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>These cyber attacks were aimed at heightening ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>A film producer said he recently ordered liquo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>Alexa is a voice-controlled virtual assistant ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>A file photo of Maharashtra home minister Anil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "7993  The meeting will be chaired by the health mini...      4\n",
       "7994  These cyber attacks were aimed at heightening ...      4\n",
       "7995  A film producer said he recently ordered liquo...      4\n",
       "7996  Alexa is a voice-controlled virtual assistant ...      4\n",
       "7997  A file photo of Maharashtra home minister Anil...      4\n",
       "\n",
       "[7998 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(articles, columns = ['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake coronavirus articles from boom\n",
    "for i in range(1,25):\n",
    "    if i==1:\n",
    "        page = requests.get('https://www.boomlive.in/search?search=coronavirus%20fake%20news')\n",
    "    else:\n",
    "        page = requests.get('https://www.boomlive.in/search?search=coronavirus%20fake%20news&search_type=all&page='+str(i))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('h2',{'class':\"entry-title\"})\n",
    "    pagelinks = []\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.boomlive.in' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        content = html.find_all('div',{'class':\"story\"})\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake news from politifact\n",
    "for i in range(1,30):\n",
    "    pagelinks = []\n",
    "    if i==1:\n",
    "        page  = requests.get('https://www.politifact.com/factchecks/list/?category=truth-o-meter&ruling=false')\n",
    "    else:\n",
    "        page = requests.get('https://www.politifact.com/factchecks/list/?page=' + str(i) + '&category=truth-o-meter&ruling=false')\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('div', {'class':\"m-statement__quote\"})\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.politifact.com' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        html = BeautifulSoup(requests.get(page).content, 'html.parser')\n",
    "        content = html.find_all('article', {'class':\"m-textblock\"})[0]\n",
    "        content = content.find_all('html')\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9916</th>\n",
       "      <td>[The newest tool in climate skeptics' arsenal:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9917</th>\n",
       "      <td>[On his Dec. 8, 2009, radio show, conservative...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9918</th>\n",
       "      <td>[After the New Orleans Saints squeaked by with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>[Fox News Channel host Glenn Beck recently fou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>[At a jobs summit at the White House on Dec. 3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "9916  [The newest tool in climate skeptics' arsenal:...      0\n",
       "9917  [On his Dec. 8, 2009, radio show, conservative...      0\n",
       "9918  [After the New Orleans Saints squeaked by with...      0\n",
       "9919  [Fox News Channel host Glenn Beck recently fou...      0\n",
       "9920  [At a jobs summit at the White House on Dec. 3...      0\n",
       "\n",
       "[9921 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(articles, columns = ['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20,30):\n",
    "    if i==1:\n",
    "        page = requests.get('https://www.boomlive.in/fake-news')\n",
    "    else:\n",
    "        page = requests.get('https://www.boomlive.in/fake-news/'+str(i))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('h2',{'class':\"entry-title\"})\n",
    "    pagelinks = []\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append('https://www.boomlive.in' + url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        r = urllib.request.Request(page, headers= {'User-Agent' : 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        news = urllib.request.urlopen(r)\n",
    "        html = BeautifulSoup(news, 'html.parser')\n",
    "        content = html.find_all('div',{'class':\"story\"})\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8791</th>\n",
       "      <td>[A nearly one year old video from Uttar Prades...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8792</th>\n",
       "      <td>[Viral social media posts claiming Shadab Faro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8793</th>\n",
       "      <td>[A set of eight images showing various seized ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8794</th>\n",
       "      <td>[1. Video Shows Chinese Policemen Killing Coro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>[Twitter handle History of India (@RealHistori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Label\n",
       "0     [During anti-police-brutality protests that sw...      0\n",
       "1     [In June 2020, a rumor started to circulate on...      0\n",
       "2     [Rumors are surging in the wake of George Floy...      0\n",
       "3     [On June 4, 2020, a security fence was erected...      0\n",
       "4     [In early June 2020, social media users shared...      0\n",
       "...                                                 ...    ...\n",
       "8791  [A nearly one year old video from Uttar Prades...      0\n",
       "8792  [Viral social media posts claiming Shadab Faro...      0\n",
       "8793  [A set of eight images showing various seized ...      0\n",
       "8794  [1. Video Shows Chinese Policemen Killing Coro...      0\n",
       "8795  [Twitter handle History of India (@RealHistori...      0\n",
       "\n",
       "[8796 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(articles, columns=['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles on scams from ftc\n",
    "for i in range(0,30):\n",
    "    if i==0:\n",
    "        page = requests.get('https://www.consumer.ftc.gov/features/scam-alerts')\n",
    "    else:\n",
    "        page= requests.get('https://www.consumer.ftc.gov/features/scam-alerts?page='+str(i))\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    weblinks = soup.find_all('h2')[7:-3]\n",
    "    pagelinks = []\n",
    "    for link in weblinks:\n",
    "        url = link.find_all('a')[0]\n",
    "        pagelinks.append(url.get('href'))\n",
    "    for page in pagelinks:\n",
    "        html = BeautifulSoup(requests.get(page).content, 'html.parser')\n",
    "        content = html.find_all('div', {'class':\"content\"})[0]\n",
    "        clean_content = BeautifulSoup(str(content), 'html.parser').get_text()\n",
    "        text = clean_content.replace('\\n','')\n",
    "        text = text.replace('\\xa0', '')\n",
    "        articles.append((text,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10375"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in articles:\n",
    "    if len(a[0]) == 2:\n",
    "        articles.remove(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "for a in articles:\n",
    "    news.append((a[0].replace('\\t',''),a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>When you book a hotel room online, you expect ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>It’s tough enough to find a job or start your ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>The Federal Trade Commission cracked down on a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>\"There is currently money available NOW right ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>It's enough to make you sick. No sooner had th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0      [During anti-police-brutality protests that sw...      0\n",
       "1      [In June 2020, a rumor started to circulate on...      0\n",
       "2      [Rumors are surging in the wake of George Floy...      0\n",
       "3      [On June 4, 2020, a security fence was erected...      0\n",
       "4      [In early June 2020, social media users shared...      0\n",
       "...                                                  ...    ...\n",
       "10370  When you book a hotel room online, you expect ...      4\n",
       "10371  It’s tough enough to find a job or start your ...      4\n",
       "10372  The Federal Trade Commission cracked down on a...      4\n",
       "10373  \"There is currently money available NOW right ...      4\n",
       "10374  It's enough to make you sick. No sooner had th...      4\n",
       "\n",
       "[10375 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(news, columns = ['Text','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[During anti-police-brutality protests that sw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[In June 2020, a rumor started to circulate on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Rumors are surging in the wake of George Floy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[On June 4, 2020, a security fence was erected...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[In early June 2020, social media users shared...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>When you book a hotel room online, you expect ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>It’s tough enough to find a job or start your ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>The Federal Trade Commission cracked down on a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>\"There is currently money available NOW right ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>It's enough to make you sick. No sooner had th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0      [During anti-police-brutality protests that sw...      0\n",
       "1      [In June 2020, a rumor started to circulate on...      0\n",
       "2      [Rumors are surging in the wake of George Floy...      0\n",
       "3      [On June 4, 2020, a security fence was erected...      0\n",
       "4      [In early June 2020, social media users shared...      0\n",
       "...                                                  ...    ...\n",
       "10370  When you book a hotel room online, you expect ...      4\n",
       "10371  It’s tough enough to find a job or start your ...      4\n",
       "10372  The Federal Trade Commission cracked down on a...      4\n",
       "10373  \"There is currently money available NOW right ...      4\n",
       "10374  It's enough to make you sick. No sooner had th...      4\n",
       "\n",
       "[10375 rows x 2 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(news, columns = ['Text','Label'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Snopes-data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
